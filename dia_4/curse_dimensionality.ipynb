{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Curse of Dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: $P(x)$ of $x$ being at the border of a unit square\n",
    "\n",
    "Pick a random point in a unit square (1 x 1). It will have 0.4% chance of being located less than 0.001 from the border.\n",
    "\n",
    "Let's make a simulation of this scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_square(border):\n",
    "    \"\"\"\n",
    "    Visualize a square with a border and a random point\n",
    "    \"\"\"\n",
    "    \n",
    "    def draw_squares(border):\n",
    "        # draws the two squares\n",
    "        sqr = mpl.patches.Rectangle((0,0),1,1)\n",
    "        ax.add_patch(sqr)\n",
    "        sqr_2 = mpl.patches.Rectangle((0+border,0+border),1-border*2,1-border*2, color='w')\n",
    "        ax.add_patch(sqr_2)\n",
    "\n",
    "    # random point (x, y):\n",
    "    x, y = np.random.rand(2)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    draw_squares(border)\n",
    "    ax.plot([x],[y], c='r',marker='x', markersize=12)\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_ylim(0,1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_square(0.01)  # border = 0.001 is not visible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of the random point $x$ to land in the blue zone is:\n",
    "\n",
    "### with Monte Carlo simulation (naive approach):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(n, matrix):\n",
    "    count = 0\n",
    "    for _ in range(n):   \n",
    "        sample = np.random.choice(matrix.flat)\n",
    "        if sample == 0:\n",
    "            count += 1\n",
    "    return count/n\n",
    "    #print(f'probabilty of point in border: {count/n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.zeros((1000,1000, 1000), dtype=np.bool)\n",
    "mat[1:-1,1:-1,1:-1] = 1  # left border with 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.2 ms ± 419 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit simulate(10000, mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the problem of this approach is that with 4 dimension ($1000^4$) we run out of memory.\n",
    "\n",
    "Each element of `np.bool` is a byte. So we need 1000^4 bytes which is **931.32257 Gb** ...a bit too much.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_2(d, n):\n",
    "    count = 0\n",
    "    for _ in range(n):\n",
    "        vec = np.random.rand(d)\n",
    "        min = np.min(vec)\n",
    "        max = np.max(vec)\n",
    "        if min <= 0.001 or max >= 0.999:\n",
    "            count += 1\n",
    "    return count/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 ms ± 1.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit simulate_2(1000, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With math:\n",
    "\n",
    "Let's start with 1-D example:\n",
    "\n",
    "We have a segment of length 1. And we crop two small segments of 0.001 at both ends of the the segment. We will call $B$ the small segments ($B = 0.002$) and the long segment $A$:\n",
    "\n",
    "$$ A_1 + B_1 = 1 $$\n",
    "\n",
    "then, \n",
    "\n",
    "$$ A_1 = 1 - B_1 $$\n",
    "\n",
    "$$ A_1 = 0.998 $$\n",
    "\n",
    "The probability of picking a random point that lays in the borders is:\n",
    "\n",
    "$$P(x \\in B) = 1 - 0.998 = 0.002 $$\n",
    "$$P(x \\in B) = B$$\n",
    "\n",
    "Which is the length of the borders.\n",
    "\n",
    "For the 2-D example simply square the inner segment $A^2 = 0.996$ and do difference with $1$ to get the area of the border:\n",
    "\n",
    "$$ B_2 = 1 - 0.998^2 = 0.004 $$\n",
    "\n",
    "Generalizing for arbitrary number of dimensions $d$:\n",
    "\n",
    "$$ B_d = 1 - 0.998^d $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the equaiton\n",
    "def border_prob(d):\n",
    "    prob = 1 - (0.998)**d\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0039959999999999996"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_prob(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most points in a high-dimensional hypercube are very close to the border!. \n",
    "> Anyone you know is probably an extremist in at least one dimension (e.g., how much sugar they put in their coffee), if you considere enough dimensions\n",
    "\n",
    "Aurélien Geron in Hands on Machine Learning with Scikit-Learn & TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance example\n",
    "\n",
    "A more troublesome effect of high dimensional spaces: pick two random points in a unit square, the mean distance between these two points will be 0.52. In a unit 3D cube, the average distance will be 0.66. Let's see what happens in higher dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "def mean_dist(d, n, p=2):\n",
    "    \"\"\"\n",
    "    mean distance between pairs of random points in d dimensional space\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    d: int, number of dimensions\n",
    "    \n",
    "    n: int, number of pair of points (high == precision)\n",
    "    \n",
    "    p: int, subindex for the L_p norm or distance.\n",
    "        L_2 (p=2) is euclidian distance, L_1 (p=1) is manhattan,\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple(float, float)\n",
    "      mean distance of the n pair of points.\n",
    "      difference max dist and min dist\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "    for _ in range(n):\n",
    "        a = np.random.rand(int(d))\n",
    "        b = np.random.rand(int(d))\n",
    "        distances.append(np.linalg.norm(a-b, p))\n",
    "    return np.mean(distances), max(distances) - min(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6633187391823472, 1.500782006956072)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_dist(3,10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's check the mean distance for a 1,000,000 dimensional unit hypercube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1290.955008946426, 1.0134068228655906)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_dist(1e7, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points in this high dimensional dataset are likely to be far apart. This means that high dimensional datasets are at risk of being very sparse. \n",
    "\n",
    "How can we solve this problem?\n",
    "\n",
    "+ Gather more data:\n",
    "\n",
    "+ Reduce dimensions: projection or manifold learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
